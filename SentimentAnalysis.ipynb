{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Marzi\\VSCode\\TopicModeling_SentimentAnalysis_twitter\\venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Marzi\\VSCode\\TopicModeling_SentimentAnalysis_twitter\\venv\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "c:\\Marzi\\VSCode\\TopicModeling_SentimentAnalysis_twitter\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.read_csv('data//All_tweets_public.csv')\n",
    "df = df2.head(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example tweets and topics\n",
    "tweets = df['Text']\n",
    "topics = [\n",
    "    \"This topic likely discusses the political aspect of wildfires, including mentions of Trump, California, and climate science.\",\n",
    "    \"This topic focuses on the impact of wildfire smoke on air quality, particularly in the western United States.\",\n",
    "    \"This topic discusses forest fires, climate change, and management practices over the years.\",\n",
    "    \"This topic highlights a specific event where a gender reveal party in California and Oregon sparked wildfires.\",\n",
    "    \"This topic relates to the spread of wildfires, their impact on forests and people, and mentions COVID-19.\"\n",
    "]\n",
    "\n",
    "\n",
    "# Encode tweets and topics\n",
    "tweet_embeddings = model.encode(tweets)\n",
    "topic_embeddings = model.encode(topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DateTime        UserID       UserName  \\\n",
      "0  9/3/2020 23:59  8.430000e+17    CalBluebird   \n",
      "1  9/3/2020 23:59  8.731312e+06  DenverChannel   \n",
      "2  9/3/2020 23:58  1.303508e+08    StephonJS87   \n",
      "3  9/3/2020 23:57  1.160000e+18   roboticscats   \n",
      "4  9/3/2020 23:54  1.678503e+07      WMAR2News   \n",
      "\n",
      "                                                Text  RT  Likes     Dates  \\\n",
      "0  b'As fires loomed closer to the sanctuary of C...   1      1  9/3/2020   \n",
      "1  b'On Friday, the BLM and White River National ...   0      2  9/3/2020   \n",
      "2  b'@sunbIasts He already did that last nightm i...   0      0  9/3/2020   \n",
      "3  b'If you see a #wildfire, you click the wildfi...   1      2  9/3/2020   \n",
      "4  b'Wildfires are causing concern for sensitive ...   0      0  9/3/2020   \n",
      "\n",
      "       Time   Topic 1   Topic 2   Topic 3   Topic 4   Topic 5  Assigned Topic  \n",
      "0  23:59:00  0.348584  0.273918  0.257527  0.320500  0.305050               1  \n",
      "1  23:59:00  0.241776  0.186462  0.283772  0.197116  0.311043               5  \n",
      "2  23:58:00  0.324949  0.210221  0.258624  0.252132  0.348937               5  \n",
      "3  23:57:00  0.396654  0.366781  0.327452  0.363544  0.405793               5  \n",
      "4  23:54:00  0.561442  0.655321  0.478694  0.478754  0.584365               2  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msarv\\AppData\\Local\\Temp\\ipykernel_6324\\1458709953.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'Topic {i+1}'] = similarity_scores[:, i].cpu().numpy()\n",
      "C:\\Users\\msarv\\AppData\\Local\\Temp\\ipykernel_6324\\1458709953.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'Topic {i+1}'] = similarity_scores[:, i].cpu().numpy()\n",
      "C:\\Users\\msarv\\AppData\\Local\\Temp\\ipykernel_6324\\1458709953.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'Topic {i+1}'] = similarity_scores[:, i].cpu().numpy()\n",
      "C:\\Users\\msarv\\AppData\\Local\\Temp\\ipykernel_6324\\1458709953.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'Topic {i+1}'] = similarity_scores[:, i].cpu().numpy()\n",
      "C:\\Users\\msarv\\AppData\\Local\\Temp\\ipykernel_6324\\1458709953.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'Topic {i+1}'] = similarity_scores[:, i].cpu().numpy()\n",
      "C:\\Users\\msarv\\AppData\\Local\\Temp\\ipykernel_6324\\1458709953.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Assigned Topic'] = similarity_scores.argmax(dim=1).cpu().numpy() + 1\n"
     ]
    }
   ],
   "source": [
    "# Compute cosine similarity between tweets and topics\n",
    "similarity_scores = util.pytorch_cos_sim(tweet_embeddings, topic_embeddings)\n",
    "\n",
    "# Add similarity scores for each topic as new columns in the DataFrame\n",
    "for i in range(len(topics)):\n",
    "    df[f'Topic {i+1}'] = similarity_scores[:, i].cpu().numpy()\n",
    "\n",
    "# Optionally, you can also add a column that assigns each tweet to the most similar topic\n",
    "df['Assigned Topic'] = similarity_scores.argmax(dim=1).cpu().numpy() + 1\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>UserID</th>\n",
       "      <th>UserName</th>\n",
       "      <th>Text</th>\n",
       "      <th>RT</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Time</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Assigned Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/3/2020 23:59</td>\n",
       "      <td>8.430000e+17</td>\n",
       "      <td>CalBluebird</td>\n",
       "      <td>b'As fires loomed closer to the sanctuary of C...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9/3/2020</td>\n",
       "      <td>23:59:00</td>\n",
       "      <td>0.348584</td>\n",
       "      <td>0.273918</td>\n",
       "      <td>0.257527</td>\n",
       "      <td>0.320500</td>\n",
       "      <td>0.305050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9/3/2020 23:59</td>\n",
       "      <td>8.731312e+06</td>\n",
       "      <td>DenverChannel</td>\n",
       "      <td>b'On Friday, the BLM and White River National ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9/3/2020</td>\n",
       "      <td>23:59:00</td>\n",
       "      <td>0.241776</td>\n",
       "      <td>0.186462</td>\n",
       "      <td>0.283772</td>\n",
       "      <td>0.197116</td>\n",
       "      <td>0.311043</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/3/2020 23:58</td>\n",
       "      <td>1.303508e+08</td>\n",
       "      <td>StephonJS87</td>\n",
       "      <td>b'@sunbIasts He already did that last nightm i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9/3/2020</td>\n",
       "      <td>23:58:00</td>\n",
       "      <td>0.324949</td>\n",
       "      <td>0.210221</td>\n",
       "      <td>0.258624</td>\n",
       "      <td>0.252132</td>\n",
       "      <td>0.348937</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9/3/2020 23:57</td>\n",
       "      <td>1.160000e+18</td>\n",
       "      <td>roboticscats</td>\n",
       "      <td>b'If you see a #wildfire, you click the wildfi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9/3/2020</td>\n",
       "      <td>23:57:00</td>\n",
       "      <td>0.396654</td>\n",
       "      <td>0.366781</td>\n",
       "      <td>0.327452</td>\n",
       "      <td>0.363544</td>\n",
       "      <td>0.405793</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9/3/2020 23:54</td>\n",
       "      <td>1.678503e+07</td>\n",
       "      <td>WMAR2News</td>\n",
       "      <td>b'Wildfires are causing concern for sensitive ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9/3/2020</td>\n",
       "      <td>23:54:00</td>\n",
       "      <td>0.561442</td>\n",
       "      <td>0.655321</td>\n",
       "      <td>0.478694</td>\n",
       "      <td>0.478754</td>\n",
       "      <td>0.584365</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>9/3/2020 14:45</td>\n",
       "      <td>1.031219e+09</td>\n",
       "      <td>BobPace1</td>\n",
       "      <td>b'Colorado Forest Service Launches County-by-C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9/3/2020</td>\n",
       "      <td>14:45:00</td>\n",
       "      <td>0.434292</td>\n",
       "      <td>0.420359</td>\n",
       "      <td>0.445230</td>\n",
       "      <td>0.351297</td>\n",
       "      <td>0.482402</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>9/3/2020 14:45</td>\n",
       "      <td>2.369777e+07</td>\n",
       "      <td>shirgoldbird</td>\n",
       "      <td>b\"Seattle being a dumpster fire of a city does...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9/3/2020</td>\n",
       "      <td>14:45:00</td>\n",
       "      <td>0.406735</td>\n",
       "      <td>0.423552</td>\n",
       "      <td>0.292846</td>\n",
       "      <td>0.305282</td>\n",
       "      <td>0.313673</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>9/3/2020 14:44</td>\n",
       "      <td>3.126206e+09</td>\n",
       "      <td>UCMercedLorena</td>\n",
       "      <td>b'Wildfire and the damage it causes will incre...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9/3/2020</td>\n",
       "      <td>14:44:00</td>\n",
       "      <td>0.414786</td>\n",
       "      <td>0.433675</td>\n",
       "      <td>0.349119</td>\n",
       "      <td>0.345291</td>\n",
       "      <td>0.458483</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>9/3/2020 14:44</td>\n",
       "      <td>8.340000e+17</td>\n",
       "      <td>bsunderlinmsp</td>\n",
       "      <td>b'@umairfan @KendraWrites One of my microbiolo...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9/3/2020</td>\n",
       "      <td>14:44:00</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>-0.040024</td>\n",
       "      <td>-0.052222</td>\n",
       "      <td>0.069113</td>\n",
       "      <td>0.078906</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>9/3/2020 14:44</td>\n",
       "      <td>3.154950e+09</td>\n",
       "      <td>chocoIate_miIk</td>\n",
       "      <td>b'TW// fire , animals , burnt , wildfire , hur...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9/3/2020</td>\n",
       "      <td>14:44:00</td>\n",
       "      <td>0.387987</td>\n",
       "      <td>0.337089</td>\n",
       "      <td>0.381954</td>\n",
       "      <td>0.336452</td>\n",
       "      <td>0.405095</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           DateTime        UserID        UserName  \\\n",
       "0    9/3/2020 23:59  8.430000e+17     CalBluebird   \n",
       "1    9/3/2020 23:59  8.731312e+06   DenverChannel   \n",
       "2    9/3/2020 23:58  1.303508e+08     StephonJS87   \n",
       "3    9/3/2020 23:57  1.160000e+18    roboticscats   \n",
       "4    9/3/2020 23:54  1.678503e+07       WMAR2News   \n",
       "..              ...           ...             ...   \n",
       "995  9/3/2020 14:45  1.031219e+09        BobPace1   \n",
       "996  9/3/2020 14:45  2.369777e+07    shirgoldbird   \n",
       "997  9/3/2020 14:44  3.126206e+09  UCMercedLorena   \n",
       "998  9/3/2020 14:44  8.340000e+17   bsunderlinmsp   \n",
       "999  9/3/2020 14:44  3.154950e+09  chocoIate_miIk   \n",
       "\n",
       "                                                  Text  RT  Likes     Dates  \\\n",
       "0    b'As fires loomed closer to the sanctuary of C...   1      1  9/3/2020   \n",
       "1    b'On Friday, the BLM and White River National ...   0      2  9/3/2020   \n",
       "2    b'@sunbIasts He already did that last nightm i...   0      0  9/3/2020   \n",
       "3    b'If you see a #wildfire, you click the wildfi...   1      2  9/3/2020   \n",
       "4    b'Wildfires are causing concern for sensitive ...   0      0  9/3/2020   \n",
       "..                                                 ...  ..    ...       ...   \n",
       "995  b'Colorado Forest Service Launches County-by-C...   0      0  9/3/2020   \n",
       "996  b\"Seattle being a dumpster fire of a city does...   0      0  9/3/2020   \n",
       "997  b'Wildfire and the damage it causes will incre...   1      2  9/3/2020   \n",
       "998  b'@umairfan @KendraWrites One of my microbiolo...   0      3  9/3/2020   \n",
       "999  b'TW// fire , animals , burnt , wildfire , hur...   1      1  9/3/2020   \n",
       "\n",
       "         Time   Topic 1   Topic 2   Topic 3   Topic 4   Topic 5  \\\n",
       "0    23:59:00  0.348584  0.273918  0.257527  0.320500  0.305050   \n",
       "1    23:59:00  0.241776  0.186462  0.283772  0.197116  0.311043   \n",
       "2    23:58:00  0.324949  0.210221  0.258624  0.252132  0.348937   \n",
       "3    23:57:00  0.396654  0.366781  0.327452  0.363544  0.405793   \n",
       "4    23:54:00  0.561442  0.655321  0.478694  0.478754  0.584365   \n",
       "..        ...       ...       ...       ...       ...       ...   \n",
       "995  14:45:00  0.434292  0.420359  0.445230  0.351297  0.482402   \n",
       "996  14:45:00  0.406735  0.423552  0.292846  0.305282  0.313673   \n",
       "997  14:44:00  0.414786  0.433675  0.349119  0.345291  0.458483   \n",
       "998  14:44:00  0.021626 -0.040024 -0.052222  0.069113  0.078906   \n",
       "999  14:44:00  0.387987  0.337089  0.381954  0.336452  0.405095   \n",
       "\n",
       "     Assigned Topic  \n",
       "0                 1  \n",
       "1                 5  \n",
       "2                 5  \n",
       "3                 5  \n",
       "4                 2  \n",
       "..              ...  \n",
       "995               5  \n",
       "996               2  \n",
       "997               5  \n",
       "998               5  \n",
       "999               5  \n",
       "\n",
       "[1000 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
